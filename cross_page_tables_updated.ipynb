{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify cross-page tables based on rules\n",
    "\n",
    "This sample demonstrates how to use the output of Layout model and some business rules to identify cross-page tables. Once idenfied, it can be further processed to merge these tables and keep the semantics of a table.\n",
    "\n",
    "Depending on your document format, there can be different rules applied to idenfity a cross-page table. This sample shows how to use the following rules to identify cross-page tables:\n",
    "\n",
    "- If the 2 tables appear in consecutive pages\n",
    "- And there's only page header, page footer or page number beteen them\n",
    "- And the tables have the same number of columns\n",
    "\n",
    "You can customize the rules based on your scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- An Azure AI Document Intelligence resource - follow [this document](https://learn.microsoft.com/azure/ai-services/document-intelligence/create-document-intelligence-resource?view=doc-intel-4.0.0) to create one if you don't have.\n",
    "- Get familiar with the output structure of Layout model - complete [this quickstart](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/quickstarts/get-started-sdks-rest-api?view=doc-intel-4.0.0&pivots=programming-language-python#layout-model) to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install azure-ai-documentintelligence python-dotenv azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code loads environment variables using the `dotenv` library and sets the necessary environment variables for Azure services.\n",
    "The environment variables are loaded from the `.env` file in the same directory as this notebook.\n",
    "\"\"\"\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "endpoint = \"your-endpoint\"\n",
    "key = \"your-documentint-key\"\n",
    "file_path = \"your-filename.pdf\"\n",
    "custom_model_name = 'your-custom-model-name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_page_numbers(table):\n",
    "    \"\"\"\n",
    "    Returns a list of page numbers where the table appears.\n",
    "\n",
    "    Args:\n",
    "        table: The table object.\n",
    "\n",
    "    Returns:\n",
    "        A list of page numbers where the table appears.\n",
    "    \"\"\"\n",
    "    return [region.page_number for region in table.bounding_regions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_span_offsets(table):\n",
    "    \"\"\"\n",
    "    Calculates the minimum and maximum offsets of a table's spans.\n",
    "\n",
    "    Args:\n",
    "        table (Table): The table object containing spans.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the minimum and maximum offsets of the table's spans.\n",
    "    \"\"\"\n",
    "    min_offset = table.spans[0].offset\n",
    "    max_offset = table.spans[0].offset + table.spans[0].length\n",
    "\n",
    "    for span in table.spans:\n",
    "        if span.offset < min_offset:\n",
    "            min_offset = span.offset\n",
    "        if span.offset + span.length > max_offset:\n",
    "            max_offset = span.offset + span.length\n",
    "\n",
    "    return min_offset, max_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_merge_table_candidates(tables):\n",
    "    \"\"\"\n",
    "    Finds the merge table candidates based on the given list of tables.\n",
    "\n",
    "    Parameters:\n",
    "    tables (list): A list of tables.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of merge table candidates, where each candidate is a dictionary with keys:\n",
    "          - pre_table_idx: The index of the first candidate table to be merged (the other table to be merged is the next one).\n",
    "          - start: The start offset of the 2nd candidate table.\n",
    "          - end: The end offset of the 1st candidate table.\n",
    "    \"\"\"\n",
    "    merge_tables_candidates = []\n",
    "    pre_table_idx = -1\n",
    "    pre_table_page = -1\n",
    "    pre_max_offset = 0\n",
    "\n",
    "    for table_idx, table in enumerate(tables):\n",
    "        min_offset, max_offset = get_table_span_offsets(table)\n",
    "        table_page = min(get_table_page_numbers(table))\n",
    "        \n",
    "        # If there is a table on the next page, it is a candidate for merging with the previous table.\n",
    "        if table_page == pre_table_page + 1:\n",
    "            pre_table = {\"pre_table_idx\": pre_table_idx, \"start\": pre_max_offset, \"end\": min_offset}\n",
    "            merge_tables_candidates.append(pre_table)\n",
    "        \n",
    "        print(f\"Table {table_idx} has offset range: {min_offset} - {max_offset} on page {table_page}\")\n",
    "\n",
    "        pre_table_idx = table_idx\n",
    "        pre_table_page = table_page\n",
    "        pre_max_offset = max_offset\n",
    "\n",
    "    return merge_tables_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_paragraph_presence(paragraphs, start, end):\n",
    "    \"\"\"\n",
    "    Checks if there is a paragraph within the specified range that is not a page header, page footer, or page number. If this were the case, the table would not be a merge table candidate.\n",
    "\n",
    "    Args:\n",
    "        paragraphs (list): List of paragraphs to check.\n",
    "        start (int): Start offset of the range.\n",
    "        end (int): End offset of the range.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if a paragraph is found within the range that meets the conditions, False otherwise.\n",
    "    \"\"\"\n",
    "    if not paragraphs is None:\n",
    "        for paragraph in paragraphs:\n",
    "            for span in paragraph.spans:\n",
    "                if span.offset > start and span.offset < end:\n",
    "                    # The logic role of a parapgaph is used to idenfiy if it's page header, page footer, page number, title, section heading, etc. Learn more: https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/concept-layout?view=doc-intel-4.0.0#document-layout-analysis\n",
    "                    if not hasattr(paragraph, 'role'):\n",
    "                        return True\n",
    "                    elif hasattr(paragraph, 'role') and paragraph.role not in [\"pageHeader\", \"pageFooter\", \"pageNumber\"]:\n",
    "                        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_cross_page_tables():\n",
    "    \"\"\"\n",
    "    Identifies and merges tables that span across multiple pages in a document.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    document_intelligence_client = DocumentIntelligenceClient(\n",
    "        endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    # You can also use a URL instead of a local file with begin_analyze_document_from_url().\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            custom_model_name, analyze_request=f, content_type=\"application/octet-stream\"  \n",
    "        )\n",
    "\n",
    "    result = poller.result()\n",
    "\n",
    "    merge_tables_candidates = find_merge_table_candidates(result.tables)\n",
    "\n",
    "    print(\"----------------------------------------\")\n",
    "\n",
    "    for i, candidate in enumerate(merge_tables_candidates):\n",
    "        table_idx = candidate[\"pre_table_idx\"]\n",
    "        start = candidate[\"start\"]\n",
    "        end = candidate[\"end\"]\n",
    "\n",
    "       \n",
    "        has_paragraph = check_paragraph_presence(result.paragraphs, start, end)\n",
    "        # has_paragraph = False\n",
    "        # If there is no paragraph within the range and the columns of the tables match, merge the tables.\n",
    "        if not has_paragraph and result.tables[table_idx].column_count == result.tables[table_idx + 1].column_count:\n",
    "            print(f\"Merge table: {table_idx} and {table_idx + 1}\")\n",
    "            print(\"----------------------------------------\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below output points if the two tables should be merged or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 0 has offset range: 52 - 1777 on page 1\n",
      "Table 1 has offset range: 1830 - 4376 on page 2\n",
      "----------------------------------------\n",
      "Merge table: 0 and 1\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = identify_cross_page_tables()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the two Tables, one in page 1 and page 2 can be merged, apply a logic as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =['location','total','premium']\n",
    "data = {'location':[],'total':[],'premium':[]}\n",
    "\n",
    "for row in result['documents'][0]['fields']['tableLtI']['valueArray']:\n",
    "    key_list = list(row['valueObject'].keys())\n",
    "    for key in  key_list:\n",
    "        if key in columns:\n",
    "            data[key].append(row['valueObject'][key]['valueString'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>total</th>\n",
       "      <th>premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1740 WEST BROADWAY Mesa, AZ 85201 County : 13</td>\n",
       "      <td>709.00</td>\n",
       "      <td>695.00 14.00 1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11700 E. BERRY DRIVE DEWEY, AZ 86327 County 025</td>\n",
       "      <td>598.00</td>\n",
       "      <td>582.00 16.00 1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4174 EAST HUNTINGTON #A FLAGSTAFF, AZ 86004 Co...</td>\n",
       "      <td>1,191.00</td>\n",
       "      <td>1179.00 12.00 1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202 BUCKET OF BLOOD HOLBROOK, AZ 86025 County 017</td>\n",
       "      <td>631.00</td>\n",
       "      <td>619.00 12.00 1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            location     total  \\\n",
       "0      1740 WEST BROADWAY Mesa, AZ 85201 County : 13    709.00   \n",
       "1    11700 E. BERRY DRIVE DEWEY, AZ 86327 County 025    598.00   \n",
       "2  4174 EAST HUNTINGTON #A FLAGSTAFF, AZ 86004 Co...  1,191.00   \n",
       "3  202 BUCKET OF BLOOD HOLBROOK, AZ 86025 County 017    631.00   \n",
       "\n",
       "              premium  \n",
       "0   695.00 14.00 1.00  \n",
       "1   582.00 16.00 1.00  \n",
       "2  1179.00 12.00 1.00  \n",
       "3   619.00 12.00 1.00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
